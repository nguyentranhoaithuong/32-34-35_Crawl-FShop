
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import os
import re
import time

output_folder = "D:\\Khai pha web\\CK\\Cmt"

if not os.path.exists(output_folder):
    os.makedirs(output_folder)

def clean_filename(filename):
    cleaned_filename = re.sub(r'[\\/*?:"<>|]', '', filename)
    return cleaned_filename

def CrawlComment(driver):
    comments = []

    try:
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'root-review')))
        review_element = driver.find_element(By.ID, 'root-review')
        comment_elements = review_element.find_elements(By.CSS_SELECTOR, '.user-block')

        for comment_element in comment_elements:
            try:
                NguoiDung = comment_element.find_element(By.CSS_SELECTOR, '.avatar-name .text').text
                BinhLuan = comment_element.find_element(By.CSS_SELECTOR, '.avatar-para .text').text
                NgayDang = comment_element.find_element(By.CSS_SELECTOR, '.avatar-time .text.text-grayscale').text

                comment_data = f"Người dùng: {NguoiDung}\nNgày đăng: {NgayDang}\nBình luận: {BinhLuan}\n------------------------------------\n"
                comments.append(comment_data)
            except StaleElementReferenceException:
                comment_elements = review_element.find_elements(By.CSS_SELECTOR, '.user-block')
                time.sleep(1)
                continue
            except NoSuchElementException:
                pass

    except NoSuchElementException:
        pass

    return comments

def CrawlCommentAllPages():
    driver = webdriver.Chrome()

    with open('D:\\Khai pha web\\CK\\buoc1.txt', 'r') as file:
        for line in file:
            url = line.strip()
            driver.get(url)

            try:
                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'st-name')))

                TenSP = driver.find_element(By.CLASS_NAME, 'st-name').text
                TenSP = clean_filename(TenSP) 
                comments = []

                while True:
                    comments.extend(CrawlComment(driver))

                    try:
                        review_element = driver.find_element(By.ID, 'root-review')
                        next_page_element = review_element.find_element(By.CSS_SELECTOR, "ul.pagination a.pagination-link i.cm-ic-angle-right")
                        next_page_element.click()

                        time.sleep(2)
                    except NoSuchElementException:
                        break

                output_file_path = os.path.join(output_folder, f"{TenSP}.txt")
                with open(output_file_path, 'w', encoding='utf-8') as f:
                    for comment in comments:
                        f.write(comment)

            except NoSuchElementException:
                print(f"Không thể lấy dữ liệu từ {url}")

    driver.quit()

CrawlCommentAllPages()
